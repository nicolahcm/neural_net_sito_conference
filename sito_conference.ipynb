{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to do bureucracy:\n",
    "4. Prepare abstract.: add which useful use cases\n",
    "6. How long should it be the discussion?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "    - some real use cases?\n",
    "    - talk also about the paper of Mall with conformable derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First examples from Lagaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper begin without initial condition! It will be easier, if you discuss about the universal theorem!\n",
    "\n",
    "Plus some discussion on accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d\\Psi}{dx} = -\\Psi(x+\\frac{1+3x^2}{1+x+x^3}) + x^3 + x^2\\frac{1+3x^2}{1+x+x^3} + 2x$$ \n",
    "with initial condition\n",
    "$$\\Psi(0) = 1 $$\n",
    "The analytical solution is given by \n",
    "$$\\bar{\\Psi} = \\frac{e^{-\\frac{x^2}{2}}}{1+x+x^3} + x^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(76.0611, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(46.0487, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.6649, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4218, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8642, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(30.1924, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5869, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5366, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3415, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1811, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1537, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0289, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0242, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0230, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0217, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0206, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0199, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0189, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0164, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0191, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0132, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0112, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3936, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0089, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0054, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0067, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0152, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1972, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0079, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1291, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.9208e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.8033e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.7854e-05, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: 1 + x * N(x) \n",
    "f = lambda x, Psi: x**3 + 2*x + x**2*(1+3*x**2)/(1+x+x**3)-Psi*(x + (1+3*x**2)/(1+x+x**3))\n",
    "def loss(x):\n",
    "    outputs = Psi_t(x) \n",
    "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    final_loss = torch.mean( ( Psi_t_x - f(x, outputs) )  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return  final_loss\n",
    "x_train = np.linspace(0, 2, 10)[:, None]\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.LBFGS(N.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(50):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yy = Psi_t(torch.Tensor(x_train)).numpy()  # Neural network\n",
    "yt = np.exp(-x_train**2/2)/(1+x_train+x_train**2)+x_train**2 #f..... of x_train... Analyticas solution\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(x_train, yt, label='True')\n",
    "ax.plot(x_train, yy, '--', label='Neural network approximation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$Psi(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{d\\psi}{dx} = e^{\\frac{-x}{5}}\\cos(x) - \\frac{\\psi}{5} = f $$ \n",
    "$$ \\psi(0) = 0$$\n",
    "\n",
    "With analytical solution given by \n",
    "$$ \\bar{\\Psi} = e^{-x/5}\\cos(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.4459, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1701, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1129, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0047, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0041, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.6914e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.6069e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.4814e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.3883e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.7514e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.8711e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9834e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3288e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.9813e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.1925e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.3637e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2461e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2419e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2400e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2176e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.1788e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0440e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.8213e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4896e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9086e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1880e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.5882e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4697e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3169e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3744e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2872e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0056e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8855e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5658e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3936e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2886e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1667e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0542e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8895e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6378e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4244e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3070e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5962e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2575e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2292e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1902e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1693e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1443e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1263e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2480e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1052e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0953e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7530e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0915e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0885e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1217e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0804e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0763e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0749e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0723e-06, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: x * N(x) \n",
    "f = lambda x, Psi: torch.exp(-x/5)*torch.cos(x) - Psi/5\n",
    "def loss(x):\n",
    "    outputs = Psi_t(x) \n",
    "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    final_loss = torch.mean( ( Psi_t_x - f(x, outputs) )  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return  final_loss\n",
    "x_train = np.linspace(0, 2, 10)[:, None]\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.LBFGS(N.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(5):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yy = Psi_t(torch.Tensor(x_train)).numpy()  # Neural network\n",
    "yt = np.exp(-x_train/5)*np.sin(x_train) #f..... of x_train... Analyticas solution\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(x_train, yt, label='True')\n",
    "ax.plot(x_train, yy, '--', label='Neural network approximation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$Psi(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 (from the website): second order differential equation\n",
    "https://www.analyticsvidhya.com/blog/2021/09/ordinary-differential-equations-made-easy-with-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d^2\\Psi}{dx^2} = -1 $$\n",
    "with Dirichlet boundary conditions:\n",
    "$$\\Psi(0) = 0 $$\n",
    "$$\\Psi(1) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(2.4125, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5480, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1074, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.1113e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0597e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1875e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.7777e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9180e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2679e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2316e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: x * (1-x) * N(x) \n",
    "f = lambda x, Psi: -1\n",
    "def loss(x):\n",
    "    outputs = Psi_t(x) \n",
    "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    Psi_t_x_x = torch.autograd.grad(Psi_t_x, x, grad_outputs=torch.ones_like(Psi_t_x), create_graph=True )[0]\n",
    "    final_loss = torch.mean( ( Psi_t_x_x - f(x, outputs) )  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return  final_loss\n",
    "x_train = np.linspace(0, 1, 100)[:, None]\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.LBFGS(N.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(5):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yy = Psi_t(torch.Tensor(x_train)).numpy()  # Neural network\n",
    "yt = 1/2*(-x_train**2 + x_train) #f..... of x_train... Analyticas solution\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(x_train, yt, label='True')\n",
    "ax.plot(x_train, yy, '--', label='Neural network approximation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$Psi(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: integral equation (Volterra type, but also fredholm ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider\n",
    "$$ \\Psi(t) = \\alpha \\int_0^t \\Psi(s) + 1\\,ds$$\n",
    "which is obtained by\n",
    "$$\\Psi' = \\alpha \\Psi $$ \n",
    "with initial condition $$\\Psi(0) = 1 $$\n",
    "The analytical solution is $$\\Psi(t) = e^{\\alpha t}$$\n",
    "Let's solve it as integral equation. Here approximating the integral will be done with rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(1.1044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1061, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1165, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1273, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1500, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1619, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4279, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4475, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4675, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4880, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5090, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5305, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5524, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5749, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5978, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6213, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6453, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6698, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7204, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7466, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8284, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8569, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8859, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9156, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9459, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9768, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0083, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0405, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0734, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1069, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1411, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1761, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2117, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2480, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2851, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3229, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3615, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4410, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4820, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5237, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6097, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6540, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6991, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.7452, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.7921, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8399, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8886, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9383, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9889, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0405, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.1465, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2566, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3132, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3708, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4294, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4891, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.5499, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6118, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6748, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.7389, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.8041, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.8704, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9379, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0763, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.1473, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2194, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2928, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.3673, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4431, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5982, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.6776, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.7582, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.8401, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.9232, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0076, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0932, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.1801, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2682, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.3576, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.4483, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.5402, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.6333, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.7277, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.8234, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.9203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.0184, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.1178, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.2184, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.3202, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.4232, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.5274, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.6327, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.7392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.8469, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.9556, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.0655, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.1764, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.2884, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.4013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.5153, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.6303, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.7461, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.8629, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.9805, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.0989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.2181, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.3381, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.4587, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(203.3953, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(205.2686, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(207.1403, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(209.0103, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(210.8781, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(212.7433, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(214.6056, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(216.4647, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(218.3203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(220.1718, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(222.0190, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(223.8615, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(225.6987, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(227.5304, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(229.3560, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(231.1752, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(232.9874, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(234.7923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(236.5893, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(238.3780, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(240.1579, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(241.9284, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(243.6891, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(245.4394, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(247.1788, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(248.9067, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(250.6226, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(252.3259, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(254.0161, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(255.6925, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(257.3546, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(259.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(260.6334, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(262.2488, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(263.8474, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(265.4286, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(266.9916, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(268.5359, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(270.0609, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(271.5657, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(273.0498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(274.5125, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(275.9530, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(277.3708, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(278.7651, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(280.1352, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(281.4804, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(282.8000, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(284.0933, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(285.3597, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(286.5983, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(287.8086, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(288.9897, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(290.1411, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(291.2620, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(292.3517, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(293.4095, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(294.4347, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(295.4267, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(296.3848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(297.3083, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(298.1966, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(299.0490, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(299.8648, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(300.6436, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(301.3845, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(302.0872, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(302.7509, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.3750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.9591, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.5026, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(305.0049, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.4656, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.8842, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.2601, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.5930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.8824, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.1280, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.3293, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.4861, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.5978, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.6644, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.6854, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.6606, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.5898, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.4729, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.3095, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.0997, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.8432, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.5400, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.1900, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.7934, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.3499, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.8596, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.3228, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.7393, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.1095, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(302.4335, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(301.7114, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(300.9435, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(300.1300, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(299.2713, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(298.3677, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(297.4196, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(296.4273, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(295.3913, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(294.3120, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(293.1900, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(292.0257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(290.8197, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(289.5725, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(288.2850, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(286.9575, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(285.5908, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(284.1857, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(282.7427, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(281.2627, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(279.7465, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(278.1948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(276.6086, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(274.9885, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(273.3355, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5291.3574, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5311.3950, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5353.9443, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5424.8530, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5532.1699, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5687.3350, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5907.2412, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6217.9277, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6661.0132, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7300.0273, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8139.7974, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5514.3037, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2710.9663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2700.9685, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2671.1470, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2634.5249, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2599.5623, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2567.2891, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2537.0408, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2508.2842, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2480.7266, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2454.1282, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2428.3450, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2403.2529, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2378.7954, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2354.8701, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2331.4280, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2308.4182, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2285.8005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2263.5376, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2241.5945, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2219.9531, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2198.5796, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2177.4590, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2156.5698, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2135.8931, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2115.4099, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2095.1226, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2074.9890, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2055.0193, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2035.1958, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2015.5096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1995.9514, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1976.5150, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1957.1837, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1937.9563, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1918.8320, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1899.7928, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1880.8386, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1861.9614, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1843.1609, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1824.4241, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1805.7540, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1787.1418, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1768.5859, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1750.0825, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1731.6274, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1713.2144, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1694.8466, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1676.5210, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1658.2327, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1639.9750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1621.7529, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1603.5621, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1585.4028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1567.2645, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1549.1587, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1531.0781, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1513.0297, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1494.9960, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1476.9883, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1459.0055, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1441.0485, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1423.1014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1405.1941, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1387.3026, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1369.4425, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1351.6040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1333.7970, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1316.0145, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1298.2554, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1280.5272, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1262.8436, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1245.1949, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1227.5774, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1209.9989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1192.4663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1174.9861, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1157.5457, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1140.1620, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1122.8352, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1105.5690, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1088.3657, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1071.2325, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1054.1761, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1037.1887, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1020.2781, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1003.4623, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(986.7427, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(970.1064, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(953.5474, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(937.1733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(920.8608, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(904.6764, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(888.6165, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(872.6738, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(856.8670, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(841.1957, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(825.6628, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(810.2869, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(795.0472, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(779.9662, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(765.0923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(750.4110, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(735.8904, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(721.5586, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(707.4168, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(693.4269, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(679.6174, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(665.9656, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(652.4605, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(639.0750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(625.8340, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(612.7146, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(599.6793, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(586.7889, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(573.9807, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(561.2615, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(548.6161, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(536.0553, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(523.5809, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(511.1757, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(498.8461, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(486.5855, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(474.4126, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(462.3358, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(450.3384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(438.4247, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(426.6250, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(414.9298, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(403.3453, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(391.8663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(380.5221, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(369.2887, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(358.1859, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(347.2253, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(336.3815, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(325.6880, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(315.1142, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.6848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(294.3909, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(284.2257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(274.1999, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(264.3046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(254.5548, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(244.9323, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(235.4412, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(226.0832, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(216.8511, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(207.7463, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(198.7559, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(189.8717, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(181.0785, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(172.3416, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(163.6431, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(154.8634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(145.8744, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(136.2201, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(124.3303, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(85.1510, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(44.2143, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(39.9898, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(790.0250, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(736.8533, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(731.7312, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(700.3611, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(690.5109, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(682.6038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(674.5610, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(666.3948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(658.1331, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(649.7613, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(641.2552, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(632.5886, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(623.7447, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(614.7040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(605.4539, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(595.9873, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(586.3005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(576.3988, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(566.2946, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(556.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(545.5634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(534.9989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(524.3530, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(513.6678, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(502.9888, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(492.3537, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(481.8063, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(471.3720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(461.0817, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(450.9507, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(440.9923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(431.2139, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(421.6188, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(412.2044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(402.9703, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(393.9099, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(385.0217, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(376.2987, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(367.7372, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(359.3340, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(351.0840, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(342.9875, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(335.0395, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(327.2429, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(319.5923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(312.0911, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.7379, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(297.5331, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(290.4768, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(283.5699, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(276.8124, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(270.2048, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(263.7472, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(257.4392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(251.2802, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(245.2711, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(239.4092, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(233.6940, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(228.1235, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(222.6968, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(217.4102, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(212.2634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(207.2521, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(202.3747, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(197.6274, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(193.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(188.5117, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(184.1364, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(179.8797, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(175.7363, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(171.7046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(167.7801, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(163.9596, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(160.2406, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(156.6189, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(153.0926, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(149.6573, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(146.3106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(143.0491, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(139.8712, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(136.7723, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(133.7519, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(130.8038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(127.9321, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(125.1225, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(122.3930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(119.7051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(117.1231, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(114.5168, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(112.1269, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(109.4473, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(107.4198, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(103.5317, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(102.0612, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(93.5644, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(91.7559, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(89.4843, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(87.5570, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(85.5525, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(83.6345, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(81.7319, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(79.8796, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(78.0468, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(76.1860, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(74.5799, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(72.8589, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(71.2990, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(69.6381, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(68.1051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(66.5113, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(65.0000, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(63.4680, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(61.9863, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(60.5096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(59.0673, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(57.6417, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(56.2439, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(54.8660, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(53.5127, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(52.1804, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(50.8743, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(49.5924, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(48.3441, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(47.1171, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(45.9395, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(44.7122, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(43.7103, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(40.1387, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(38.9819, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(38.0874, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(35.3115, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(34.2205, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(33.3454, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(31.8032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(30.9119, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(29.5360, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(28.6733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(27.2643, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(26.4328, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(25.2848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(24.5467, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(23.3388, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(22.6719, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(21.7318, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(21.1716, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(20.0548, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(19.5285, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(18.9462, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(18.5218, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(17.5764, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(17.1528, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(16.7413, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(16.3716, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(15.9506, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(15.6425, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(14.8744, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(14.5383, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(14.2498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(13.8982, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(13.6464, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(13.1823, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.9268, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.6373, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.4107, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.0643, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.8483, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.5413, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.3392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.0374, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.8433, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.5743, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.3915, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.1282, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.9527, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.7116, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.5448, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.3130, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.1531, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.9357, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.7829, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.5760, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.4296, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.2334, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.0930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.9065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.7718, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.5944, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.4652, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.2961, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.1720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.0106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.8911, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.7370, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.6211, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.4750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.3674, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.2097, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.1052, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.9672, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.8679, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.7320, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.6361, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.5101, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.4181, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2980, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2093, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0952, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0098, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.9013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.8189, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.7162, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.6365, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5396, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4624, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.3710, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2960, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2100, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.1368, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0559, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9845, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.8385, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.7659, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6982, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6291, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.5634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4972, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4336, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3701, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3092, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2473, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.1904, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.1254, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0749, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9829, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9323, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8697, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8243, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.7407, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6942, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6387, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5961, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5297, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4886, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4287, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3896, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3281, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2907, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2341, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1980, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1420, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0532, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9416, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8917, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8621, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8127, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7837, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7416, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7146, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6699, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6432, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6055, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5803, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5428, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5185, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4832, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4599, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4260, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1582, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1332, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1153, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0915, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0742, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0515, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0348, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0131, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9970, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9763, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9608, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9410, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9260, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8926, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8745, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8606, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8429, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8296, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8123, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7996, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7827, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7705, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7541, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7424, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7267, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7154, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6895, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6752, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6646, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6510, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6408, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6278, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6179, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6056, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5960, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5843, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5751, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5640, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5550, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5445, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5357, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5172, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5077, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4994, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4904, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4824, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4738, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4659, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4577, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4501, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4422, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4349, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4272, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4127, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.4062, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3981, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3831, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3776, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3679, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3625, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3541, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3491, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3406, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3357, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3279, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3232, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3156, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3111, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2995, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2928, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2887, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2821, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2782, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2717, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2679, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2620, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2583, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2525, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2490, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2436, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2401, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2350, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2317, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2268, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2236, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2190, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2159, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2114, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2084, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2042, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1972, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1944, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1906, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1878, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1841, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1815, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1780, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1754, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1721, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1696, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1639, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1609, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1585, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1556, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1533, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1505, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1483, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1456, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1435, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1408, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1388, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1363, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1343, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1318, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1299, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1276, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1234, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1217, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1194, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1177, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1155, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1139, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1117, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1102, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1066, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1031, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0979, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0965, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0934, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0889, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0448, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0302, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0293, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0287, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0283, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0278, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0275, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0270, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0266, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0261, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0258, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0253, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0250, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0245, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0242, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0238, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0235, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0231, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0227, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0223, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0220, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0216, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0214, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0210, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0207, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0197, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0191, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0188, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0185, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0182, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0179, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0177, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0173, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0171, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0168, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0166, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0163, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0161, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0158, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0156, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0153, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0151, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0148, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0146, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0144, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0142, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0139, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0137, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0135, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0133, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0131, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0129, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0127, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0125, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0123, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0121, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0119, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0118, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0115, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0114, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0112, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0110, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0108, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0104, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0103, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0101, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0099, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0097, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0094, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0093, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0091, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0090, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0088, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0087, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0085, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0084, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0082, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0079, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0078, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0077, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0075, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0074, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0073, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0069, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0068, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0067, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0066, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0064, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0063, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0062, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0058, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0058, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0057, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0056, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0055, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0054, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0053, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0052, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0050, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0049, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0048, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0047, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0047, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0045, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0042, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0042, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0041, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0039, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0037, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0037, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0036, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0035, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0035, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0034, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0034, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0031, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0031, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0029, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0029, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0020, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0020, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0020, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "\n",
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: N(x)\n",
    "f_integrand = lambda x, Psi: alpha*Psi\n",
    "Psi_real = lambda x: torch.exp(alpha*x)\n",
    "\n",
    "n_points = 20\n",
    "x_train = np.linspace(0, 2, n_points)[:, None]       # Train from 0 to 2\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "delta_x = 2/(n_points-1)\n",
    "\n",
    "def loss(x):\n",
    "    outputs = N(x)   \n",
    "    sum_heights = N(x)\n",
    "    for i in range(n_points):                    \n",
    "        sum_heights[i] = torch.sum(outputs[0:i])   #Sum of Heights of the left-rectangles\n",
    "    final_loss = torch.mean( (outputs - alpha*delta_x*sum_heights - 1)  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return final_loss\n",
    "optimizer = torch.optim.LBFGS(N.parameters(), lr=0.01)\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(200):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb2147ddd8>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xx = x.tolist()\n",
    "yy = Psi_t(x)[:,0].tolist()\n",
    "yt = Psi_real(x).tolist()\n",
    "ax.plot(xx, yy)\n",
    "ax.plot(xx,yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do. Then compare with other integration methods, the gauss-legendre. And to do. Solve the previous examples using integral equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with fractional Riccati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.5183, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.6380e-05, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.3736e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1373e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0165e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0154e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0143e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0008e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.7765e-07, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.1002e-07, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.7094e-07, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2717e-07, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4636e-07, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "final timing: 0.927605390548706\n"
     ]
    }
   ],
   "source": [
    "T = 2\n",
    "alpha = 0.64\n",
    "lambd = 0.2\n",
    "mu = 0\n",
    "nu = 0.2\n",
    "\n",
    "N = nn.Sequential(nn.Linear(1, 10), nn.Sigmoid(),nn.Linear(10,1, bias=False))\n",
    "Psi_t = lambda x: x**alpha*N(x)   #x**alpha * N(x)  # Trial solution\n",
    "\n",
    "n_points = 65\n",
    "\n",
    "n_legendre = 15\n",
    "\n",
    "nodes, weights = scipy.special.roots_legendre(n_legendre)\n",
    "weights_tensor = torch.tensor(weights)[:,None].float()\n",
    "nodes_tensor = torch.tensor(nodes)[:,None].float()\n",
    "\n",
    "def f(x):\n",
    "    return x**(1/1)\n",
    "\n",
    "x_train = f(np.linspace(0, T**1, n_points)[:, None])\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "\n",
    "def g(x):\n",
    "    result = lambd*Psi_t(x)**2+mu*Psi_t(x)+nu\n",
    "    return result\n",
    "\n",
    "def g_ia(s,t):\n",
    "    return (t-s)**(alpha-1)*g(s)\n",
    "\n",
    "def loss(x):\n",
    "    \n",
    "    outputs = Psi_t(x)\n",
    "    \n",
    "    \n",
    "    # Notice that the below is indipendent by how x is distributed (could be a different distribution of points)\n",
    "    integrals_vector = x.double() # just copying x, but then we will change it, only to have something with same dimen.\n",
    "    for i in range(n_points):\n",
    "        if i == 0:\n",
    "            integrals_vector[0][0] = 0\n",
    "        else:\n",
    "            t = x[i]\n",
    "            transf_x_vals_tens = nodes_tensor*t/2 + t/2\n",
    "\n",
    "            integrands_values = g_ia(transf_x_vals_tens, t)\n",
    "            # print(\"integrands_values\", integrands_values)\n",
    "            integral_at_time_t = 1/math.gamma(alpha)*t/2*torch.sum(integrands_values * weights_tensor)\n",
    "\n",
    "            integrals_vector[i][0] = integral_at_time_t\n",
    "        \n",
    "    final_loss = torch.mean((outputs - integrals_vector)**2)\n",
    "    \n",
    "    print('loss is', final_loss)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "optimizer = torch.optim.LBFGS(N.parameters(), lr=1)\n",
    "\n",
    "def closure():\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    \n",
    "    return l\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "optimizer.step(closure)\n",
    "print(\"final timing:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "theta = 0.9\n",
    "\n",
    "r_max = 105\n",
    "\n",
    "def returns_all_the_first_r_max_coefficients_as_list_2():\n",
    "    ''' Run this function. This returns the list of coefficients. Up to a_k where \n",
    "        k = r_max. '''\n",
    "    \n",
    "    coefficients = [np.nan]*(r_max+1)\n",
    "\n",
    "    a0 = 0 \n",
    "    a1 = nu/math.gamma(alpha+1)\n",
    "    coefficients[0] = a0\n",
    "    coefficients[1] = a1\n",
    "    \n",
    "    \n",
    "    def recursive_convol_coefficients(list_of_coefficients, k):\n",
    "        ''' return a*_k^2  given the first k-1 a_m coefficients. \n",
    "        k is the coefficient a^_k^2 to be returned'''\n",
    "        if k==1:\n",
    "            return 0\n",
    "        else: \n",
    "            sum = 0\n",
    "            for l in range(1,k):\n",
    "                a_l = list_of_coefficients[l]\n",
    "                a_k_l = list_of_coefficients[k-l]\n",
    "                sum += a_l*a_k_l\n",
    "            return sum\n",
    "    \n",
    "    \n",
    "    def recursive_coefficients(list_of_coefficients, n):\n",
    "        ''' Given the convoluted coefficient a_k_star_quadro, \n",
    "        Given also n, the coefficient a_n to be returned... Note that n = k+1 !!! \n",
    "        returns a_k'''\n",
    "        k = n-1 # n-1 = k\n",
    "        a_k_star_quadro = recursive_convol_coefficients(list_of_coefficients, k) \n",
    "        a_k = list_of_coefficients[k]  \n",
    "        a_n = (lambd*a_k_star_quadro + mu*a_k)*math.gamma(alpha*k + 1)/math.gamma(alpha*k + alpha + 1)\n",
    "    \n",
    "        return a_n\n",
    "\n",
    "    for i in range(2, r_max+1):\n",
    "        coefficients[i] = recursive_coefficients( coefficients, i)\n",
    "        \n",
    "    return coefficients\n",
    "\n",
    "coeff = returns_all_the_first_r_max_coefficients_as_list_2()\n",
    "\n",
    "coeff_df = pd.DataFrame(coeff)\n",
    "\n",
    "a_r_max = coeff[-1]\n",
    "a_primo_r_max = a_r_max*math.gamma(alpha*r_max+1)/(math.gamma(alpha*r_max-alpha+1)*(alpha*r_max+1-alpha))\n",
    "\n",
    "R_estimate = abs(a_primo_r_max)**(-1/(alpha*r_max))\n",
    "\n",
    "r_0 = math.log(epsilon*(1-theta))/alpha/math.log(theta)-1\n",
    "r_0 = int(np.round(r_0)+1)\n",
    "\n",
    "slicing = slice(0,r_0)\n",
    "\n",
    "coeff_truncated = coeff[slicing]\n",
    "\n",
    "def poly(lst, x):   \n",
    "    ''' Evaluate the polynomial with coefficients lst= [a0,a1,a2,...] in x\n",
    "    Pol: a0 + a1*x**alpha + a2*x**(2*alpha) + .... '''\n",
    "    n, tmp = 0, 0\n",
    "    for a in lst:\n",
    "        tmp = tmp + (a * (x**(n*alpha)))\n",
    "        n += 1\n",
    "\n",
    "    return tmp\n",
    "\n",
    "def computing_psi_n(n):\n",
    "    ''' Just Give n. This function makes use of the parameters. Then also of the list \"coeff_truncated\" \n",
    "    '''\n",
    "    \n",
    "    disc_times = [k*T/n for k in range(0,n+1)]\n",
    "    \n",
    "    theta = 0.9\n",
    "    #theta = theta_n(n) # Only In This Example, Because The Theta fixed at the beginning would go out otherwise!\n",
    "    \n",
    "    \n",
    "    \n",
    "    k_0 = math.floor(R_estimate*theta*n/T)  ### Up to t_k_0 we will use truncated series. Then Euler Schema\n",
    "    \n",
    "    if k_0 >= len(disc_times):\n",
    "        t_k_0 = \"Doesn't exist t_k_0\"\n",
    "    else: \n",
    "        t_k_0 = disc_times[k_0]\n",
    "    \n",
    "    values_assumed_in_disc_times = [np.nan]*(n+1)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Here We Evaluate The Truncated Series!\n",
    "    \n",
    "    if k_0 <= len(disc_times):\n",
    "        for k in range(0,k_0+1):\n",
    "            values_assumed_in_disc_times[k] = poly(coeff_truncated, disc_times[k])\n",
    "    else:\n",
    "        for k in range(0,n):\n",
    "            values_assumed_in_disc_times[k] = poly(coeff_truncated, disc_times[k])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Here Instead We Use The Euler Scheme\n",
    "    def compute_c_i(alpha, l):\n",
    "        if l == 0:\n",
    "            return 1\n",
    "        else: \n",
    "            return (l+1)**alpha - l**alpha\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range(k_0+1, n+1):\n",
    "        factor_1 = 1/math.gamma(alpha + 1)*(T/n)**alpha\n",
    "        addend_2 = nu*k**alpha \n",
    "        addend_3 = 0\n",
    "        for l in range(1,k):\n",
    "            psi_n_t_l = values_assumed_in_disc_times[l]\n",
    "            addend_3 += compute_c_i(alpha, k-l-1)*psi_n_t_l*(lambd*psi_n_t_l + mu)\n",
    "        \n",
    "        factor_2 = addend_2 + addend_3\n",
    "        \n",
    "        result = factor_1*factor_2\n",
    "        \n",
    "        values_assumed_in_disc_times[k] = result\n",
    "            \n",
    "    \n",
    "    print(\"t_k0=\", t_k_0)\n",
    "    \n",
    "    #return disc_times, values_assumed_in_disc_times\n",
    "    return pd.DataFrame({\"time\": disc_times, \"value\": values_assumed_in_disc_times}), t_k_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.8337548150555"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_k0= Doesn't exist t_k_0\n"
     ]
    }
   ],
   "source": [
    "comparison = computing_psi_n(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_euler_scheme = comparison[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "xx = x.tolist()\n",
    "yy = Psi_t(x)[:,0].tolist()\n",
    "# yt = Psi_real(x).tolist()\n",
    "ax.plot(xx, yy, \"x\",  label='Neural network approximation')\n",
    "ax.plot(results_euler_scheme.time, results_euler_scheme.value, \"-\",  label='Analytical soluton')\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "if type(comparison[1]) == type(2.0):\n",
    "    ax.axvline(x = comparison[1], linewidth=1, color='r')\n",
    "    \n",
    "fig.savefig(\"fract_ric.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "xx = x.tolist()\n",
    "yy = Psi_t(x)[:,0].tolist()\n",
    "# yt = Psi_real(x).tolist()\n",
    "#ax.plot(xx, yy, \"x\",  label='Neural network approximation')\n",
    "ax.plot(results_euler_scheme.time, np.abs(yy-results_euler_scheme.value)/results_euler_scheme.value, \"+\",  label='relative difference between nn and analytical solution')\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "if type(comparison[1]) == type(2.0):\n",
    "    ax.axvline(x = comparison[1], linewidth=1, color='r')\n",
    "    \n",
    "fig.savefig(\"fract_ric_errors.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
