{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to do bureucracy:\n",
    "1. ask for registration in the site.\n",
    "2. ask rokhlin the difference between plenary report etc...\n",
    "3. ask rokhlin to put him in collaborators and do not pay for the fee of subscription\n",
    "4. Prepare abstract.: add which useful use cases\n",
    "5. Ask what to prepare to Rokhlin. There is written but I do not understand: abstract now. The presentation can also do later right? You can also ask to Багдасарян Анжела Левоновна or  inftech@sfedu.ru\n",
    "6. How long should it be the discussion?\n",
    "\n",
    "### for the other conference with karap.\n",
    "\n",
    "1. do an abstract of 1 page.\n",
    "2. ask if it works. \n",
    "3. ask when to prepare the presentation and if they actually do publish.\n",
    "\n",
    "### other things to ask to svetlana evgenivna:\n",
    "\n",
    "1. to count olympiads in the list they write\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for the conference. Title idea: \"Neural Networks to solve numerically ordinary, partial differential equations and volterra integral equations\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to test before writing: Change the plots so that do not look like the article on internet!\n",
    "\n",
    "    - solving normal differential riccati. This is a special case of fractional Riccati. Show fract. Riccati\n",
    "    - solving a partial diff. eq.: solving diffusion equation.\n",
    "    - some real use cases?\n",
    "    - talk also about the paper of Mall with conformable derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First examples from Lagaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper begin without initial condition! It will be easier, if you discuss about the universal theorem!\n",
    "\n",
    "Plus some discussion on accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d\\Psi}{dx} = -\\Psi(x+\\frac{1+3x^2}{1+x+x^3}) + x^3 + x^2\\frac{1+3x^2}{1+x+x^3} + 2x$$ \n",
    "with initial condition\n",
    "$$\\Psi(0) = 1 $$\n",
    "The analytical solution is given by \n",
    "$$\\bar{\\Psi} = \\frac{e^{-\\frac{x^2}{2}}}{1+x+x^3} + x^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(76.0611, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(46.0487, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.6649, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4218, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8642, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(30.1924, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5869, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5366, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3415, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1811, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1537, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0289, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0242, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0230, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0217, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0206, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0199, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0189, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0164, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0191, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0132, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0112, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3936, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0089, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0054, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0067, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0152, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1972, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0079, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1291, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.9208e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.8033e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.7854e-05, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: 1 + x * N(x) \n",
    "f = lambda x, Psi: x**3 + 2*x + x**2*(1+3*x**2)/(1+x+x**3)-Psi*(x + (1+3*x**2)/(1+x+x**3))\n",
    "def loss(x):\n",
    "    outputs = Psi_t(x) \n",
    "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    final_loss = torch.mean( ( Psi_t_x - f(x, outputs) )  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return  final_loss\n",
    "x_train = np.linspace(0, 2, 10)[:, None]\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.LBFGS(N.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(50):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yy = Psi_t(torch.Tensor(x_train)).numpy()  # Neural network\n",
    "yt = np.exp(-x_train**2/2)/(1+x_train+x_train**2)+x_train**2 #f..... of x_train... Analyticas solution\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(x_train, yt, label='True')\n",
    "ax.plot(x_train, yy, '--', label='Neural network approximation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$Psi(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{d\\psi}{dx} = e^{\\frac{-x}{5}}\\cos(x) - \\frac{\\psi}{5} = f $$ \n",
    "$$ \\psi(0) = 0$$\n",
    "\n",
    "With analytical solution given by \n",
    "$$ \\bar{\\Psi} = e^{-x/5}\\cos(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.4459, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1701, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1129, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0047, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0041, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.6914e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.6069e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.4814e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.3883e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.7514e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.8711e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9834e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3288e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.9813e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.1925e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.3637e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2461e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2419e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2400e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2176e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.1788e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0440e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.8213e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4896e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9086e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1880e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.5882e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4697e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3169e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3744e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2872e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0056e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8855e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5658e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3936e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2886e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1667e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0542e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8895e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6378e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4244e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3070e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5962e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2575e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2292e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1902e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1693e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1443e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1263e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2480e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1052e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0953e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7530e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0915e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0885e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1217e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0804e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0763e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0749e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0723e-06, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: x * N(x) \n",
    "f = lambda x, Psi: torch.exp(-x/5)*torch.cos(x) - Psi/5\n",
    "def loss(x):\n",
    "    outputs = Psi_t(x) \n",
    "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    final_loss = torch.mean( ( Psi_t_x - f(x, outputs) )  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return  final_loss\n",
    "x_train = np.linspace(0, 2, 10)[:, None]\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.LBFGS(N.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(5):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yy = Psi_t(torch.Tensor(x_train)).numpy()  # Neural network\n",
    "yt = np.exp(-x_train/5)*np.sin(x_train) #f..... of x_train... Analyticas solution\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(x_train, yt, label='True')\n",
    "ax.plot(x_train, yy, '--', label='Neural network approximation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$Psi(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 (from the website): second order differential equation\n",
    "https://www.analyticsvidhya.com/blog/2021/09/ordinary-differential-equations-made-easy-with-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d^2\\Psi}{dx^2} = -1 $$\n",
    "with Dirichlet boundary conditions:\n",
    "$$\\Psi(0) = 0 $$\n",
    "$$\\Psi(1) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(2.4125, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5480, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1074, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.1113e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0597e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1875e-05, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.7777e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9180e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2679e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2316e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2305e-06, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: x * (1-x) * N(x) \n",
    "f = lambda x, Psi: -1\n",
    "def loss(x):\n",
    "    outputs = Psi_t(x) \n",
    "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    Psi_t_x_x = torch.autograd.grad(Psi_t_x, x, grad_outputs=torch.ones_like(Psi_t_x), create_graph=True )[0]\n",
    "    final_loss = torch.mean( ( Psi_t_x_x - f(x, outputs) )  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return  final_loss\n",
    "x_train = np.linspace(0, 1, 100)[:, None]\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.LBFGS(N.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(5):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yy = Psi_t(torch.Tensor(x_train)).numpy()  # Neural network\n",
    "yt = 1/2*(-x_train**2 + x_train) #f..... of x_train... Analyticas solution\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(x_train, yt, label='True')\n",
    "ax.plot(x_train, yy, '--', label='Neural network approximation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$Psi(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: integral equation (Volterra type, but also fredholm ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider\n",
    "$$ \\Psi(t) = \\alpha \\int_0^t \\Psi(s) + 1\\,ds$$\n",
    "which is obtained by\n",
    "$$\\Psi' = \\alpha \\Psi $$ \n",
    "with initial condition $$\\Psi(0) = 1 $$\n",
    "The analytical solution is $$\\Psi(t) = e^{\\alpha t}$$\n",
    "Let's solve it as integral equation. Here approximating the integral will be done with rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(1.1044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1061, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1165, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1273, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1500, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1619, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4279, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4475, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4675, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4880, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5090, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5305, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5524, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5749, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5978, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6213, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6453, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6698, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7204, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7466, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8284, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8569, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8859, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9156, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9459, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9768, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0083, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0405, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0734, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1069, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1411, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1761, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2117, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2480, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2851, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3229, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3615, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4410, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4820, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5237, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6097, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6540, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6991, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.7452, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.7921, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8399, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8886, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9383, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9889, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0405, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.1465, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2566, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3132, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3708, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4294, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4891, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.5499, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6118, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6748, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.7389, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.8041, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.8704, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9379, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0763, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.1473, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2194, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2928, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.3673, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4431, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5982, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.6776, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.7582, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.8401, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.9232, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0076, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0932, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.1801, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2682, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.3576, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.4483, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.5402, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.6333, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.7277, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.8234, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.9203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.0184, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.1178, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.2184, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.3202, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.4232, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.5274, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.6327, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.7392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.8469, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.9556, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.0655, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.1764, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.2884, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.4013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.5153, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.6303, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.7461, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.8629, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.9805, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.0989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.2181, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.3381, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.4587, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(203.3953, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(205.2686, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(207.1403, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(209.0103, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(210.8781, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(212.7433, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(214.6056, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(216.4647, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(218.3203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(220.1718, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(222.0190, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(223.8615, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(225.6987, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(227.5304, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(229.3560, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(231.1752, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(232.9874, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(234.7923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(236.5893, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(238.3780, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(240.1579, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(241.9284, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(243.6891, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(245.4394, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(247.1788, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(248.9067, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(250.6226, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(252.3259, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(254.0161, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(255.6925, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(257.3546, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(259.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(260.6334, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(262.2488, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(263.8474, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(265.4286, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(266.9916, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(268.5359, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(270.0609, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(271.5657, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(273.0498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(274.5125, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(275.9530, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(277.3708, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(278.7651, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(280.1352, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(281.4804, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(282.8000, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(284.0933, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(285.3597, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(286.5983, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(287.8086, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(288.9897, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(290.1411, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(291.2620, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(292.3517, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(293.4095, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(294.4347, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(295.4267, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(296.3848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(297.3083, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(298.1966, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(299.0490, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(299.8648, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(300.6436, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(301.3845, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(302.0872, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(302.7509, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.3750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.9591, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.5026, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(305.0049, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.4656, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.8842, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.2601, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.5930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.8824, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.1280, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.3293, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.4861, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.5978, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.6644, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.6854, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.6606, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.5898, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.4729, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.3095, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(307.0997, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.8432, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.5400, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(306.1900, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.7934, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(305.3499, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.8596, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.3228, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.7393, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(303.1095, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(302.4335, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(301.7114, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(300.9435, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(300.1300, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(299.2713, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(298.3677, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(297.4196, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(296.4273, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(295.3913, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(294.3120, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(293.1900, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(292.0257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(290.8197, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(289.5725, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(288.2850, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(286.9575, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(285.5908, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(284.1857, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(282.7427, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(281.2627, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(279.7465, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(278.1948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(276.6086, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(274.9885, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(273.3355, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5291.3574, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5311.3950, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5353.9443, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5424.8530, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5532.1699, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5687.3350, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5907.2412, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6217.9277, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6661.0132, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7300.0273, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8139.7974, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5514.3037, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2710.9663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2700.9685, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2671.1470, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2634.5249, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2599.5623, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2567.2891, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2537.0408, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2508.2842, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2480.7266, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2454.1282, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2428.3450, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2403.2529, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2378.7954, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2354.8701, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2331.4280, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2308.4182, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2285.8005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2263.5376, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2241.5945, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2219.9531, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2198.5796, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2177.4590, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2156.5698, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2135.8931, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2115.4099, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2095.1226, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2074.9890, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2055.0193, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2035.1958, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2015.5096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1995.9514, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1976.5150, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1957.1837, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1937.9563, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1918.8320, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1899.7928, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1880.8386, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1861.9614, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1843.1609, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1824.4241, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1805.7540, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1787.1418, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1768.5859, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1750.0825, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1731.6274, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1713.2144, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1694.8466, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1676.5210, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1658.2327, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1639.9750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1621.7529, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1603.5621, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1585.4028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1567.2645, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1549.1587, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1531.0781, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1513.0297, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1494.9960, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1476.9883, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1459.0055, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1441.0485, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1423.1014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1405.1941, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1387.3026, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1369.4425, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1351.6040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1333.7970, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1316.0145, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1298.2554, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1280.5272, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1262.8436, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1245.1949, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1227.5774, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1209.9989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1192.4663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1174.9861, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1157.5457, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1140.1620, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1122.8352, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1105.5690, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1088.3657, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1071.2325, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1054.1761, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1037.1887, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1020.2781, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1003.4623, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(986.7427, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(970.1064, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(953.5474, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(937.1733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(920.8608, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(904.6764, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(888.6165, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(872.6738, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(856.8670, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(841.1957, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(825.6628, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(810.2869, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(795.0472, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(779.9662, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(765.0923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(750.4110, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(735.8904, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(721.5586, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(707.4168, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(693.4269, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(679.6174, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(665.9656, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(652.4605, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(639.0750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(625.8340, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(612.7146, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(599.6793, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(586.7889, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(573.9807, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(561.2615, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(548.6161, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(536.0553, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(523.5809, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(511.1757, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(498.8461, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(486.5855, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(474.4126, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(462.3358, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(450.3384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(438.4247, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(426.6250, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(414.9298, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(403.3453, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(391.8663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(380.5221, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(369.2887, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(358.1859, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(347.2253, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(336.3815, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(325.6880, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(315.1142, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.6848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(294.3909, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(284.2257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(274.1999, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(264.3046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(254.5548, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(244.9323, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(235.4412, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(226.0832, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(216.8511, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(207.7463, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(198.7559, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(189.8717, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(181.0785, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(172.3416, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(163.6431, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(154.8634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(145.8744, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(136.2201, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(124.3303, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(85.1510, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(44.2143, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(39.9898, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(790.0250, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(736.8533, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(731.7312, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(700.3611, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(690.5109, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(682.6038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(674.5610, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(666.3948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(658.1331, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(649.7613, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(641.2552, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(632.5886, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(623.7447, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(614.7040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(605.4539, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(595.9873, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(586.3005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(576.3988, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(566.2946, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(556.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(545.5634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(534.9989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(524.3530, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(513.6678, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(502.9888, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(492.3537, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(481.8063, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(471.3720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(461.0817, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(450.9507, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(440.9923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(431.2139, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(421.6188, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(412.2044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(402.9703, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(393.9099, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(385.0217, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(376.2987, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(367.7372, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(359.3340, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(351.0840, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(342.9875, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(335.0395, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(327.2429, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(319.5923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(312.0911, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(304.7379, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(297.5331, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(290.4768, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(283.5699, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(276.8124, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(270.2048, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(263.7472, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(257.4392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(251.2802, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(245.2711, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(239.4092, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(233.6940, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(228.1235, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(222.6968, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(217.4102, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(212.2634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(207.2521, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(202.3747, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(197.6274, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(193.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(188.5117, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(184.1364, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(179.8797, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(175.7363, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(171.7046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(167.7801, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(163.9596, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(160.2406, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(156.6189, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(153.0926, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(149.6573, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(146.3106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(143.0491, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(139.8712, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(136.7723, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(133.7519, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(130.8038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(127.9321, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(125.1225, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(122.3930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(119.7051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(117.1231, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(114.5168, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(112.1269, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(109.4473, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(107.4198, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(103.5317, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(102.0612, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(93.5644, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(91.7559, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(89.4843, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(87.5570, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(85.5525, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(83.6345, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(81.7319, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(79.8796, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(78.0468, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(76.1860, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(74.5799, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(72.8589, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(71.2990, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(69.6381, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(68.1051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(66.5113, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(65.0000, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(63.4680, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(61.9863, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(60.5096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(59.0673, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(57.6417, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(56.2439, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(54.8660, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(53.5127, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(52.1804, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(50.8743, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(49.5924, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(48.3441, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(47.1171, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(45.9395, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(44.7122, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(43.7103, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(40.1387, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(38.9819, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(38.0874, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(35.3115, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(34.2205, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(33.3454, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(31.8032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(30.9119, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(29.5360, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(28.6733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(27.2643, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(26.4328, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(25.2848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(24.5467, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(23.3388, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(22.6719, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(21.7318, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(21.1716, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(20.0548, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(19.5285, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(18.9462, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(18.5218, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(17.5764, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(17.1528, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(16.7413, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(16.3716, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(15.9506, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(15.6425, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(14.8744, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(14.5383, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(14.2498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(13.8982, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(13.6464, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(13.1823, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.9268, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.6373, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.4107, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(12.0643, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.8483, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.5413, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.3392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(11.0374, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.8433, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.5743, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.3915, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(10.1282, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.9527, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.7116, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.5448, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.3130, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(9.1531, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.9357, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.7829, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.5760, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.4296, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.2334, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(8.0930, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.9065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.7718, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.5944, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.4652, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.2961, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.1720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(7.0106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.8911, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.7370, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.6211, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.4750, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.3674, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.2097, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(6.1052, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.9672, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.8679, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.7320, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.6361, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.5101, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.4181, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2980, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.2093, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0952, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(5.0098, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.9013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.8189, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.7162, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.6365, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.5396, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.4624, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.3710, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2960, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.2100, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.1368, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(4.0559, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9845, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.9081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.8385, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.7659, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6982, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.6291, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.5634, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4972, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.4336, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3701, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.3092, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.2473, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.1904, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.1254, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(3.0749, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9829, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.9323, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8697, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.8243, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.7407, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6942, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.6387, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5961, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.5297, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4886, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.4287, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3896, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.3281, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2907, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.2341, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1980, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1420, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.1081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0532, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(2.0200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9733, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.9416, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8917, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8621, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.8127, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7837, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7416, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.7146, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6699, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6432, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.6055, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5803, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5428, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.5185, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4832, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4599, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4260, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1582, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1332, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.1153, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0915, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0742, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0515, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0348, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(1.0131, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9970, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9763, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9608, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9410, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9260, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.9071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8926, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8745, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8606, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8429, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8296, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.8123, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7996, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7827, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7705, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7541, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7424, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7267, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7154, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.7004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6895, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6752, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6646, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6510, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6408, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6278, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6179, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.6056, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5960, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5843, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5751, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5640, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5550, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5445, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5357, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5172, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5077, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4994, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4904, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4824, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4738, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4659, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4577, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4501, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4422, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4349, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4272, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4127, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.4062, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3981, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3923, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3831, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3776, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3679, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3625, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3541, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3491, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3406, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3357, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3279, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3232, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3156, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3111, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2995, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2928, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2887, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2821, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2782, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2717, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2679, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2620, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2583, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2525, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2490, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2436, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2401, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2350, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2317, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2268, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2236, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2190, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2159, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2114, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2084, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2042, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.2013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1972, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1944, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1906, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1878, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1841, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1815, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1780, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1754, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1721, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1696, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1663, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1639, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1609, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1585, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1556, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1533, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1505, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1483, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1456, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1435, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1408, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1388, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1363, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1343, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1318, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1299, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1276, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1257, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1234, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1217, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1194, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1177, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1155, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1139, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1117, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1102, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1066, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1031, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0979, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0965, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0948, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0934, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0889, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0448, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0302, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0293, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0287, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0283, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0278, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0275, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0270, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0266, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0261, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0258, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0253, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0250, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0245, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0242, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0238, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0235, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0231, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0227, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0223, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0220, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0216, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0214, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0210, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0207, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0200, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0197, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0191, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0188, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0185, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0182, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0179, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0177, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0173, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0171, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0168, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0166, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0163, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0161, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0158, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0156, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0153, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0151, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0148, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0146, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0144, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0142, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0139, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0137, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0135, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0133, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0131, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0129, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0127, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0125, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0123, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0121, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0119, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0118, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0115, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0114, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0112, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0110, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0108, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0106, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0104, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0103, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0101, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0099, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0097, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0096, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0094, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0093, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0091, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0090, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0088, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0087, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0085, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0084, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0082, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0081, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0079, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0078, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0077, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0075, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0074, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0073, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0071, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0069, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0068, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0067, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0066, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0065, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0064, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0063, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0062, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0058, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0058, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0057, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0056, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0055, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0054, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0053, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0052, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0051, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0050, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0049, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0048, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0047, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0047, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0046, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0045, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0042, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0042, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0041, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0039, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0038, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0037, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0037, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0036, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0035, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0035, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0034, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0034, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0031, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0031, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0030, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0029, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0029, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0028, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0020, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0020, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0020, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.0002, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "\n",
    "N = nn.Sequential(nn.Linear(1, 5), nn.Sigmoid(), nn.Linear(5,1, bias=False))\n",
    "Psi_t = lambda x: N(x)\n",
    "f_integrand = lambda x, Psi: alpha*Psi\n",
    "Psi_real = lambda x: torch.exp(alpha*x)\n",
    "\n",
    "n_points = 200\n",
    "x_train = np.linspace(0, 2, n_points)[:, None]       # Train from 0 to 2\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True\n",
    "delta_x = 2/(n_points-1)\n",
    "\n",
    "def loss(x):\n",
    "    outputs = N(x)   \n",
    "    sum_heights = N(x)\n",
    "    for i in range(n_points):                    \n",
    "        sum_heights[i] = torch.sum(outputs[0:i])   #Sum of Heights of the left-rectangles\n",
    "    final_loss = torch.mean( (outputs - alpha*delta_x*sum_heights - 1)  ** 2)\n",
    "    print('loss is', final_loss)\n",
    "    return final_loss\n",
    "optimizer = torch.optim.LBFGS(N.parameters(), lr=0.01)\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    return l\n",
    "for i in range(200):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb2147ddd8>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xx = x.tolist()\n",
    "yy = Psi_t(x)[:,0].tolist()\n",
    "yt = Psi_real(x).tolist()\n",
    "ax.plot(xx, yy)\n",
    "ax.plot(xx,yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do. Then compare with other integration methods, the gauss-legendre. And to do. Solve the previous examples using integral equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
